{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4f2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffc39563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "my_matrix = np.loadtxt(open(\"S4AfterNor.csv\",encoding='UTF-8'),delimiter=\",\",skiprows=0)\n",
    "X, y = my_matrix[:,:-1],my_matrix[:,-1]\n",
    "Non_MI_data = np.load('Non_MI_data.npy')\n",
    "Non_MI_label = np.load('Non_MI_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6d94ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_observational=[]\n",
    "X_train_MI = np.load('MI_train_Kmeans.npy')\n",
    "X_val_MI = np.load('MI_val_Kmeans.npy')\n",
    "\n",
    "# combine valdation dataset and trianing dataset to enlarge sample for training\n",
    "X_observational = np.vstack((X_train_MI,X_val_MI))\n",
    "\n",
    "for n in range(len(X_observational)):\n",
    "    y_observational.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a060d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "X_observational = Variable(torch.from_numpy(np.array(X_observational)).float(), requires_grad=True)\n",
    "Y_observational = Variable(torch.tensor(y_observational)).float()\n",
    "    \n",
    "rand_Y = np.random.randint(0,1,(X_observational.size()[0],1))\n",
    "Y_generated = Variable(torch.tensor(rand_Y)).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fff7a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_observational=Y_observational.reshape(Y_observational.shape[0], 1)\n",
    "Y_generated=Y_generated.reshape(Y_generated.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7da3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN model design\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        nn.init.normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "def init_weights(net_layer):\n",
    "    try:\n",
    "        net_layer.apply(weights_init_normal)\n",
    "    except:\n",
    "        raise NotImplementedError('weights initialization error')\n",
    "\n",
    "def init_weights(net_layer):\n",
    "    try:\n",
    "        net_layer.apply(weights_init_normal)\n",
    "    except:\n",
    "        raise NotImplementedError('weights initialization error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "beab2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(382, 300),\n",
    "                                     nn.BatchNorm1d(300),\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.Linear(300, 75),\n",
    "                                     nn.BatchNorm1d(75),\n",
    "                                     nn.ReLU(True))\n",
    "        init_weights(self.encoder)\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Linear(75, 150),\n",
    "                                     nn.BatchNorm1d(150),\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.Linear(150, 382))\n",
    "        init_weights(self.decoder)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2ff698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.Linear(382, 200),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.BatchNorm1d(200),\n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(200, 200),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.BatchNorm1d(200),\n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(200, 200),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.BatchNorm1d(200),\n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(200, 100),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.BatchNorm1d(100),\n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(100, 100),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.BatchNorm1d(100),\n",
    "                                    nn.Linear(100, 1))\n",
    "                                    \n",
    "        init_weights(self.layer)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0fefab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = autoencoder()\n",
    "D = FCNN()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr = 0.005, weight_decay = 1e-4)\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr = 0.005, weight_decay = 1e-4)\n",
    "current_epoch = 0\n",
    "reconstructionLoss = nn.SmoothL1Loss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "MSELoss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b17f6ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training model\n",
    "G_loss = []\n",
    "G_ACC = []\n",
    "D_loss = []\n",
    "D_ACC = []\n",
    "STEP = []\n",
    "for step in range(3000):\n",
    "    for step_g in range(2):\n",
    "        \n",
    "        generated_img = G(X_observational)\n",
    "        generated_out = D(generated_img)\n",
    "        g_loss_1 = reconstructionLoss(generated_img,X_observational)\n",
    "        g_loss = criterion(generated_out,Y_observational)\n",
    "        g_loss = g_loss_1+g_loss\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "       \n",
    "        Results_G = 0 \n",
    "        for i in D(generated_img).detach().numpy():\n",
    "            if i > 0.5:\n",
    "                Results_G += 1\n",
    "        \n",
    "        ACC_G = Results_G / (X_observational.size()[0])\n",
    "    \n",
    "    \n",
    "    for step_d in range(1):\n",
    "    \n",
    "        observational_out = D(X_observational) \n",
    "\n",
    "        d_loss_observational = criterion(observational_out, Y_observational)\n",
    "        generated_out = D(generated_img.detach()) \n",
    "        d_loss_generated = criterion(generated_out, Y_generated)\n",
    "\n",
    "        d_loss = d_loss_observational + d_loss_generated \n",
    "        d_optimizer.zero_grad()  \n",
    "        d_loss.backward() \n",
    "        d_optimizer.step()\n",
    "        \n",
    "        Results_D_observational = 0 \n",
    "        Results = []\n",
    "        for i in observational_out:\n",
    "            if i > 0.5:\n",
    "                Results.append(1)\n",
    "            else:\n",
    "                Results.append(0)\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        for i in range(len(Results)):\n",
    "            if Results[i] == y[i]:\n",
    "                correct += 1\n",
    "        \n",
    "        D_observational_accuracy = correct / float(len(y))\n",
    "        \n",
    "        Results_D_generated = 0\n",
    "        for i in D(generated_img).detach().numpy():\n",
    "            if i < 0.5:\n",
    "                Results_D_generated += 1\n",
    "        D_generated_accuracy = Results_D_generated/X_observational.size()[0]\n",
    "\n",
    "        ACC_D =  (D_observational_accuracy+D_generated_accuracy)/2\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        D_loss.append(d_loss.data)\n",
    "        G_loss.append(g_loss.data)\n",
    "        STEP.append(step)\n",
    "    \n",
    "    if step%500 == 0:\n",
    "        generated_label_MI= []\n",
    "        generated_data_MI = []\n",
    "\n",
    "        for j in range(2):\n",
    "            generated_data = Variable(torch.randn(X_observational.size()[0], X_observational.size()[1]))\n",
    "            generated_data =  G(generated_data).detach().numpy()\n",
    "            for i in generated_data:\n",
    "                generated_data_MI.append(i)\n",
    "                generated_label_MI.append(1)\n",
    "        \n",
    "        X_MI=[]\n",
    "        y_MI=[]\n",
    "        X_Non_MI = []\n",
    "        y_Non_MI = []\n",
    "        for n in range(len(y)):\n",
    "            if y[n] == 1:\n",
    "                X_MI.append(X[n])\n",
    "                y_MI.append(1)\n",
    "            else:\n",
    "                X_Non_MI.append(X[n])\n",
    "                y_Non_MI.append(0)\n",
    "        np.save('MI_generated_data_'+'{}'.format(step)+'.npy', generated_data_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec98c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_label_MI= []\n",
    "generated_label_Non_MI= []\n",
    "generated_data_MI_list = []\n",
    "generated_data_Non_MI = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4acfb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "for i in range(5):\n",
    "    generated_data_MI = []\n",
    "    for j in range(8):\n",
    "        generated_data = Variable(torch.randn(X_observational.size()[0], X_observational.size()[1]))\n",
    "        generated_data =  G(generated_data).detach().numpy()\n",
    "        for i in generated_data:\n",
    "            generated_data_MI.append(i)\n",
    "            generated_label_MI.append(1)\n",
    "    generated_data_MI_list.append(generated_data_MI)\n",
    "\n",
    "X_MI=[]\n",
    "y_MI=[]\n",
    "X_Non_MI = []\n",
    "y_Non_MI = []\n",
    "for n in range(len(y)):\n",
    "    if y[n] == 1:\n",
    "        X_MI.append(X[n])\n",
    "        y_MI.append(1)\n",
    "    else:\n",
    "        X_Non_MI.append(X[n])\n",
    "        y_Non_MI.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7368f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(8):\n",
    "    generated_data = Variable(torch.randn(X_observational.size()[0], X_observational.size()[1]))\n",
    "    generated_data =  G(generated_data).detach().numpy()\n",
    "    for i in generated_data:\n",
    "        generated_data_Non_MI.append(i)\n",
    "        generated_label_Non_MI.append(1)\n",
    "\n",
    "X_MI=[]\n",
    "y_MI=[]\n",
    "X_Non_MI = []\n",
    "y_Non_MI = []\n",
    "for n in range(len(y)):\n",
    "    if y[n] == 1:\n",
    "        X_MI.append(X[n])\n",
    "        y_MI.append(1)\n",
    "    else:\n",
    "        X_Non_MI.append(X[n])\n",
    "        y_Non_MI.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb6716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "227ec76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_MI = np.vstack(generated_data_MI_list)\n",
    "generated_data_MI = generated_data_MI.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e0ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f6b97169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data and model\n",
    "np.save('MI_generated_data.npy',generated_data_MI)\n",
    "np.save('MI_generated_label.npy',generated_label_MI)\n",
    "np.save('MI_generatedl_Non_MI.npy',generated_data_Non_MI)\n",
    "np.save('MI_generated_label_Non_MI.npy',generated_label_Non_MI)\n",
    "\n",
    "torch.save(G,'G.pkl')\n",
    "torch.save(D,'D.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25e1671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model \n",
    "D = torch.load('D.pkl')\n",
    "Non_MI_data = np.load('Non_MI_data.npy')\n",
    "Non_MI_label = np.load('Non_MI_label.npy')\n",
    "MI_data = np.load('MI_data.npy')\n",
    "MI_label = np.load('MI_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dd1f6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Non_MI = Variable(torch.from_numpy(np.array(Non_MI_data)).float(), requires_grad=True)\n",
    "Y_Non_MI = Variable(torch.tensor(Non_MI_label)).float()\n",
    "X_MI = Variable(torch.from_numpy(np.array(MI_data)).float(), requires_grad=True)\n",
    "Y_MI = Variable(torch.tensor(MI_label)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f75c5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the performance of GAN\n",
    "number = 0\n",
    "for i in D(X_Non_MI).detach().numpy():\n",
    "    if i < 0.5:\n",
    "        number += 1\n",
    "ACC_D = number / len(X_Non_MI)\n",
    "\n",
    "number = 0\n",
    "for i in D(X_MI).detach().numpy():\n",
    "    if i > 0.5:\n",
    "        number += 1\n",
    "ACC_G = number / len(X_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02133413",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_D_G = np.array([ACC_D*ACC_G])\n",
    "np.save('ACC_D_G.npy',ACC_D_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66cdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
